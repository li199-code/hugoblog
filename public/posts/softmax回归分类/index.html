<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.119.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>softmax回归（分类） &middot; JasonLee</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/poole.css">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://blog.jasonleehere.com/"><h1>JasonLee</h1></a>
      <p class="lead">
      An elegant open source and mobile first theme for <a href="http://hugo.spf13.com">hugo</a> made by <a href="http://twitter.com/mdo">@mdo</a>. Originally made for Jekyll.
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="http://blog.jasonleehere.com/">Home</a> </li>
        
      </ul>
    </nav>

    <p>&copy; 2023. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>softmax回归（分类）</h1>
  <time datetime=2023-03-23T10:20:57Z class="post-date">Thu, Mar 23, 2023</time>
  <h2 id="回归和分类">回归和分类</h2>
<p>机器学习（深度学习）的任务纷繁复杂。最基础的是回归和分类。回归是预测连续值，分类是预测离散类别。</p>
<p>分类问题是多输出，因此，训练标签和模型（网络）的输出应该是多维的。<em>独热编码</em> （one-hot encoding）是一种表示多分类的方式。就是在一个向量中，将真实分类索引下的值设为1，其他是0，因此向量自身的内积为1。另外，模型的线性表示为：</p>
<p>所以，softmax也是一个单层全连接网络。</p>
<p>\begin{aligned}
o_1 &amp;= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\
o_2 &amp;= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\
o_3 &amp;= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}</p>
<h2 id="softmax函数">softmax函数</h2>
<p>分类问题的训练，可以用最大化正确分类的概率来表示。因此，要通过softmax函数将神经网络的输出$o_i$转化为0-1之间的概率。</p>
<p>\begin{equation}
\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad \text{其中}\quad \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}
\end{equation}</p>
<p>softmax可以保证输出在0-1之间，且softmax可导。</p>

</div>


    </main>

    
      
    
  </body>
</html>
