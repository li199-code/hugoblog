<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.119.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>文本分类比赛学习记录 &middot; JasonLee</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/poole.css">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="http://blog.jasonleehere.com/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://blog.jasonleehere.com/"><h1>JasonLee</h1></a>
      <p class="lead">
      An elegant open source and mobile first theme for <a href="http://hugo.spf13.com">hugo</a> made by <a href="http://twitter.com/mdo">@mdo</a>. Originally made for Jekyll.
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="http://blog.jasonleehere.com/">Home</a> </li>
        
      </ul>
    </nav>

    <p>&copy; 2023. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>文本分类比赛学习记录</h1>
  <time datetime=2023-09-06T10:54:38Z class="post-date">Wed, Sep 6, 2023</time>
  <h2 id="前言">前言</h2>
<p>本文是我对在公司参加的“ChatGPT 生成文本检测器”比赛。数据集为中文作文样本，其中从互联网上采集得到了真实作文，并且 ChatGLM-6B 生成了部分作文。参赛选手的任务是根据文本内容，区分作文的来源。但是，文本不是以内容呈现，而是一堆数字字符串，形如：[0 43 2 66]。可以推测出，每个数字代表一个汉字在语料库中的索引。</p>
<p>文本分类任务的四步：</p>
<ul>
<li>准备数据集：包括加载数据集和执行基本预处理，然后把数据集分为训练集和验证集。</li>
<li>特征工程：将原始数据集被转换为用于训练机器学习模型的平坦特征（flat features）。</li>
<li>模型训练</li>
<li>进一步提高分类器性能</li>
</ul>
<p>下面按照前面三步（省略第四步）介绍我的做法。</p>
<h2 id="准备数据集">准备数据集</h2>
<p>这一步的主要工作是读取原始文件，并划分训练集和验证集，用到的库 pandas 和 sklearn。</p>
<pre tabindex="0"><code>import pandas as pd
from sklearn import model_selection, preprocessing, naive_bayes, metrics, linear_model
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

df = pd.read_csv(&#39;train.csv&#39;)

# print(df[&#39;content&#39;])

#将数据集分为训练集和验证集
train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df[&#39;content&#39;], df[&#39;label&#39;])

# label编码为目标变量
encoder = preprocessing.LabelEncoder()
train_y = encoder.fit_transform(train_y)
valid_y = encoder.fit_transform(valid_y)
</code></pre><h2 id="特征工程">特征工程</h2>
<p>计数向量是数据集的矩阵表示，其中每行代表来自语料库的文档，每列表示来自语料库的术语，并且每个单元格表示特定文档中特定术语的频率计数：</p>
<pre tabindex="0"><code>#创建一个向量计数器对象
count_vect = CountVectorizer(analyzer=&#39;word&#39;, token_pattern=r&#39;\w{1,}&#39;)
count_vect.fit(df[&#39;content&#39;])

#使用向量计数器对象转换训练集和验证集
xtrain_count =  count_vect.transform(train_x)
xvalid_count =  count_vect.transform(valid_x)
</code></pre><h2 id="模型训练">模型训练</h2>
<p>线性分类器用于训练。</p>
<pre tabindex="0"><code>## 训练函数
def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):
    # fit the training dataset on the classifier
    classifier.fit(feature_vector_train, label)


    # predict the labels on validation dataset
    predictions = classifier.predict(feature_vector_valid)


    if is_neural_net:
        predictions = predictions.argmax(axis=-1)


    return classifier, metrics.accuracy_score(predictions, valid_y)

if __name__ == &#34;__main__&#34;:
    # classifier, accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)
    # print(&#34;NB, Count Vectors: &#34;, accuracy)

    classifier, accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)
    print(&#34;LR, Count Vectors: &#34;, accuracy)

    # csv out

    testDF = pd.read_csv(&#39;test.csv&#39;)
    test_x = testDF[&#39;content&#39;]

    #使用向量计数器对象转换测试集
    xtest_count =  count_vect.transform(test_x)

    predictions = classifier.predict(xtest_count)

    submissionDF = pd.DataFrame()
    submissionDF[&#39;name&#39;] = testDF[&#39;name&#39;]
    submissionDF[&#39;label&#39;] = predictions

    submissionDF.to_csv(&#39;LR_submission.csv&#39;, index=False)
</code></pre><h2 id="总结">总结</h2>
<p>这次是我在 NLP 领域的一次小试牛刀，主要用到了 sklearn 框架，使得代码的编写变得简单。在不需要数据清洗等步骤的情况下，通过简单的计数向量和逻辑回归就使得最终的测试集结果达到了 0.99 以上，说明本次比赛的数据还是比较简单的。</p>
<p>另外，这次比赛也改变了我对于机器学习的认知。一开始我认为这是一个有难度的任务，想去 huggingface 上找一些文本分类的模型，践行“拿来主义”。但是怎么也找不到合适的。后来，在网上搜索文本分类的解决方案，看到一个相似的任务，且用了 sklearn，很短的代码就能达到不错的效果。也许，传统机器学习的能力比我想象的强很多。</p>
<h2 id="更新">更新</h2>
<p>过了一段时间后，在接触更多 sklearn 知识后，我用 pipeline 来以更简单的方式实现：</p>
<pre tabindex="0"><code>import pandas as pd
from sklearn import model_selection, preprocessing, naive_bayes, metrics, linear_model
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.neighbors import KNeighborsClassifier  # 用于分类任务
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;train.csv&#39;)
X = df[&#39;content&#39;].values
y = df[&#39;label&#39;].values
le = preprocessing.LabelEncoder()
y = le.fit_transform(y)


#将数据集分为训练集和验证集
train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, y, random_state=43)

pipe_lr = Pipeline([(&#39;cv&#39;, CountVectorizer(analyzer=&#39;word&#39;, token_pattern=r&#39;\w{1,}&#39;)),
                    (&#39;scl&#39;, StandardScaler(with_mean=False)),
                    (&#39;clf&#39;, linear_model.LogisticRegression(max_iter=50000))])

pipe_lr.fit(train_x, train_y)
print(&#39;Test Accuracy: %.4f&#39; %pipe_lr.score(valid_x, valid_y))

## more metrics
valid_y_pred = pipe_lr.predict(valid_x)
confmat = confusion_matrix(y_true=valid_y, y_pred=valid_y_pred)
print(confmat)

print(&#39;Precision: %.3f&#39; % precision_score(y_true=valid_y, y_pred=valid_y_pred))
print(&#39;Recall: %.3f&#39; % recall_score(y_true=valid_y, y_pred=valid_y_pred))
print(&#39;F1: %.3f&#39; % f1_score(y_true=valid_y, y_pred=valid_y_pred))

## draw roc
y_probs = pipe_lr.predict_proba(valid_x)
fpr, tpr, thresholds = roc_curve(valid_y, y_probs[:, 1], pos_label=1)
roc_auc = roc_auc_score(valid_y, y_probs[:, 1])
print(&#39;auc: %.4f&#39; % roc_auc)
# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color=&#39;darkorange&#39;, lw=2, label=&#39;ROC curve (area = %.4f)&#39; % roc_auc)
plt.plot([0, 1], [0, 1], color=&#39;navy&#39;, lw=2, linestyle=&#39;--&#39;)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel(&#39;False Positive Rate&#39;)
plt.ylabel(&#39;True Positive Rate&#39;)
plt.title(&#39;Receiver Operating Characteristic&#39;)
plt.legend(loc=&#39;lower right&#39;)
plt.show()


## testset result

testDF = pd.read_csv(&#39;test.csv&#39;)
test_x = testDF[&#39;content&#39;].values

pipe_lr.fit(X, y)
predictions = pipe_lr.predict(test_x)

submissionDF = pd.DataFrame()
submissionDF[&#39;name&#39;] = testDF[&#39;name&#39;]
submissionDF[&#39;label&#39;] = predictions

submissionDF.to_csv(&#39;LR_submission.csv&#39;, index=False)
</code></pre><p>在新版本中，加入了不少指标用于衡量模型性能。更重要的是，之前在输出测试结果时，用的是训练集上训练的模型，而不是整个数据集上重新训练一次。在重新训练后，发现指标从 0.9901 来到了 0.9912，提示非常显著。这提示了我以后一定要注意这个问题。</p>

</div>


    </main>

    
      
    
  </body>
</html>
